{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SFFF       (S: starting point, safe)\n",
    "FHFH       (F: frozen surface, safe)\n",
    "FFFH       (H: hole, fall to your doom)\n",
    "HFFG       (G: goal, where the frisbee is located)\n",
    "\n",
    "Observation Space = 16\n",
    "Action Space = 4\n",
    "Reward Range = (-inf, inf)\n",
    "tStepL = 100\n",
    "Trials = 100\n",
    "rThresh = 0.78\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "x = env.reset()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "# Set learning parameters\n",
    "lr = .8 #learning rate, alpha\n",
    "y = .95 #discount factor , gamma\n",
    "num_episodes = 2000\n",
    "#create lists to contain total rewards and steps per episode\n",
    "#jList = []\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    #Reset environment and get first new observation\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "    j = 0\n",
    "    #The Q-Table learning algorithm\n",
    "    while j < 99:\n",
    "        j+=1\n",
    "        #Choose an action by greedily (with noise) picking from Q table\n",
    "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
    "        #Get new state and reward from environment\n",
    "        s1,reward,done,_ = env.step(a)\n",
    "        #Update Q-Table with new knowledge\n",
    "        Q[s,a] = Q[s,a] + lr*(reward + y*np.max(Q[s1,:]) - Q[s,a])\n",
    "        rAll += reward\n",
    "        s = s1\n",
    "        if done == True:\n",
    "            break\n",
    "    #jList.append(j)\n",
    "    rList.append(rAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.6125\n"
     ]
    }
   ],
   "source": [
    "print (\"Score over time: \" +  str(sum(rList)/num_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Q-Table Values\n",
      "[[2.75901842e-01 1.21039018e-02 8.14552873e-03 1.27054725e-02]\n",
      " [8.04461704e-03 1.26426202e-03 4.91438653e-04 2.49435802e-01]\n",
      " [1.49941406e-01 4.20927835e-03 7.86874548e-03 0.00000000e+00]\n",
      " [7.59968437e-04 0.00000000e+00 0.00000000e+00 1.21843189e-02]\n",
      " [4.15683256e-01 1.45704265e-03 1.59345611e-03 6.14573871e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.61751286e-03 2.10411731e-04 2.08092771e-05 3.52257191e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.23690707e-03 2.82054546e-04 1.32411607e-02 2.90121371e-01]\n",
      " [0.00000000e+00 1.74985059e-01 1.14980291e-04 6.03063666e-03]\n",
      " [7.47002498e-01 2.06659023e-04 0.00000000e+00 7.50964846e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.08206475e-01 0.00000000e+00]\n",
      " [0.00000000e+00 9.86463296e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Q-Table Values\")\n",
    "print (Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
